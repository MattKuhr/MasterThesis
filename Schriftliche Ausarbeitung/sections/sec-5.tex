\section{Umsetzung}
\label{sec-5}
Im Folgenden soll erläutert werden, wie der zuvor erarbeitete Lösungsansatz umgesetzt wurde. Dazu gibt das Kapitel zunächst einen Überblick über das System und dessen physikalischen Parameter sowie die Architektur der Anwendung. Danach geht das Kapitel genauer auf die Implementierung der Darstellungen und der Interaktion ein. Abschließend werden Details zur Performance genannt.

\subsection{Aufbau des Systems}
\label{sec-5-1}
Für die Umsetzung konnten zur Verfügung stehende Gerätschaften verwendet werden. Die Spule hat einen Radius von $R = 15 cm$ und 248 Windungen. Dazu kommt ein Arduino, der in den Aufbau integriert wird, um die anliegende Stromstärke zu messen und an einen Server weiterzugeben. Die Messung erfolgt, indem der Spannungsabfall über einen Widerstand gemessen wird. Der Arduino sendet die gemessenen Werte dann per USB an einen Computer. Die Schaltung ist in Abbildung \ref{img:schaltung} veranschaulicht. \\

Das System ist als Client-Server-Architektur realisiert. Ein Server erfasst und verarbeitet die in der Schaltung gemessenen Werte für die Stromstärke. Die Applikation auf der HoloLens tritt als Client auf und erfragt die aktuellen Werte vom Server. Einen Überblick über die Kommunikation gibt das Schema in Abbildung \ref{img:schaltung}. 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{images/schema/schaltung.jpg}
	\caption{Schaltungszeichnung des Experimentes. Die Spulen haben einen Radius und Abstand von 15 cm. Die Widerstände betragen $R1 = 25 \Omega$ und $R2 = 51 \Omega$.}
	\label{img:schaltung}
\end{figure}

\subsubsection{Client-Server Datenübertragung}
\label{sec-5-1-1}
Die Übertragung der Messwerte vom Arduino zur Anwendung ist so konzipiert, dass Änderungen in Echtzeit übermittelt werden, ohne das unnötiger Netzwerktraffic entsteht. Der Client betreibt ein Polling gegen den Server, der jedoch Antworten solange zurückhält, bis ein neuer, vom vorigen abweichender Wert gemessen wurde. Dieses Verhalten veranschaulicht das Sequenzdiagramm in Abbildung \ref{img:Sequenzdiagramm}. Das Vorgehen führt dazu, dass Änderungen durch den Nutzer am Regler der Spannungsquelle ohne wahrnehmbare Verzögerung auf der HoloLens ankommen.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{images/schema/Sequenzdiagramm.png}
	\caption{Sequenzdiagramm der Kommunikation zwischen Arduino, Server und HoloLens.}
	\label{img:Sequenzdiagramm}
\end{figure}

\textit{Server}\\
Der Server besteht aus zwei miteinander kommunizierenden Threads. Ein Thread übernimmt das Lesen und Verarbeiten der Rohdaten, die über die serielle Schnittstelle eintreffen. Bei signifikanten Änderungen wird der zweite Thread mittels einer gemeinsamen, synchronisierten Variablen über die neuen Werte informiert. Dieser beantwortet daraufhin einen ggf. ausstehenden Request vom Client. Ab wann eine Änderung als signifikant gewertet wird, lässt sich über einen Threshold einstellen. Der Server wurde mit Python und der Bibliothek pyserial umgesetzt.\\

\textit{Client}\\
Der Client stellt durch die Nutzung von asynchronen Anfragen sicher, dass die Anfragen nicht blockieren. Unity bietet nur einen Thread, synchrone Anfragen würden daher zu einer Blockierung des Renderprozesses führen und so die Framerate beeinträchtigen. Da die Framerate bei 60 Hz gedeckelt ist und eine Antwort frühestens im nächsten Frame bearbeitet werden kann, beträgt die minimale Antwortzeit ca. 17 ms. Das ist ausreichend, um keine wahrnehmbare Verzögerung aufkommen zu lassen, da die Paketlaufzeit in einem lokalen Netzwerk typischerweise im einstelligen Millisekundenbereich liegt. Eine zusätzliche Wartezeit zwischen Requests kann außerdem eingestellt werden.\\

\textit{Setup}\\
Damit die Kommunikation erfolgen kann, müssen initial einige Einstellungen vorgenommen werden. Auf Seiten des Servers ist dessen IP-Adresse und der COM-Port des Arduinos in eine Konfigurationsdatei einzutragen. Außerdem muss die IP-Adresse des Servers auf der HoloLens angegeben werden. Dies geschieht über die Einstellungen.

\subsubsection{Architektur der HoloLens-Anwendung}
\label{sec-5-1-2}
Der Hauptteil des Systems besteht in der auf der HoloLens laufenden Applikation. Die Anwendung basiert auf der Unity Engine und wird als UWP App bereitgestellt. Die Anwendung besteht aus drei Arten von Komponenten: Container-Objekte, Skript-Objekte und interaktive Komponenten. Erstere gruppieren zusammenhängende Darstellungen und steuern deren Verhalten. Skript-Objekte enthalten keine visuellen Objekte und dienen ausschließlich zur Umsetzung von Verhalten. Interaktive Komponenten steuern die direkte Interaktion über visuelle Elemente wie z.B das Menü und die Einstellungen. Das Schema in Abbildung \ref{img:components-schema} gibt einen Überblick über die verschiedenen Komponenten der Anwendung. Deren Aufgaben sind in der darunter zu findenden Tabelle kurz zusammengefasst.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.45\textwidth]{images/schema/components.jpg}
	\caption{Schematische Darstellung der einzelnen Komponenten. Die beigen Elemente sind Skript-Objekte und enthalten keine Darstellungen. Das Menü steuert den Ablauf der Anwendung, startet den Hauptteil, das Tracking und die Einstellungen. Dafür wird die Kontrolle an das jeweilige Objekt übergeben. Die Verbindungen bedeuten eine Kommunikation über zur Laufzeit registrierte Callbacks.}
	\label{img:components-schema}
\end{figure}


\bgroup
\setlength\extrarowheight{-2pt}
\def\arraystretch{2}
\begin{table}[H]
	\centering
	\begin{tabular}{m{2.5cm}|m{8cm}}
		Komponente & Funktion\\
		\hline
		\hline
		Menu & Hauptmenü, steuert den Ablauf der Anwendung\\
		\hline
		Settings & Lädt und speichert Einstellungen, bietet Zugang zu den Werten für andere Komponenten und steuert die Einstellungs-Oberfläche\\
		\hline
		Physics & Übernimmt alle physikalischen Berechnungen. Die physikalischen Parameter lassen sich konfigurieren.\\
		\hline
		Tracking & Führt durch den Prozess der Positionsbestimmung und setzt den World Anchor\\
		\hline
		Model Anchor & Dient als Anker- und Container-Objekt für die einzelnen Darstellungskomponenten. Dazu gehören: Verdeckungsmodell, Kompass, die Magnetfeldmodelle, die Stromrichtungsindikatoren und das Datenpanel.\\
		\hline
		Webservice & Übernimmt die Kommunikation mit dem Server und gibt erhaltene Daten weiter\\
		\hline
		Interaction & Verarbeitet Input und Ablaufsteuerung, soweit dies nicht an einem konkreten Objekt abgewickelt wird wie z.B. Spracheingabe.\\
	\end{tabular}\caption{\label{tab:components-details} Aufgaben der einzelnen Komponenten}
\end{table}
\egroup

Eine Komponente besteht aus einer Hierarchie von Unity's GameObjects, die mit entsprechenden Skripten versehen sind. Die Komponenten kommunizieren auf unterschiedliche Weise miteinander. Die Behandlung von Events z.B. aufgrund von Nutzereingaben oder neuen Messwerten erfolgt über Callbacks. Manche Komponenten sind auch Singletons, auf die direkt zugegriffen werden kann, wie z.B. die Einstellungen.

\subsection{Implementierung}
\label{sec-5-2}
Die Umsetzung erfolgte mit Unity 2017.4.18f1, dem Mixed Reality Toolkit 4.3.0 sowie Version 10.0.17134.0 des Windows SDK. Im Folgenden soll die Umsetzung der Darstellung und anschließend die der Interaktion beschrieben werden.

\subsubsection{Implementierung der Darstellungen}
\label{sec-5-2-2}
Die Darstellungen sind hierarchisch unterhalb eines Anker-Objektes angeordnet. Dynamische Elemente, wie z.B. die Felddarstellungen werden zur Laufzeit in dafür vorgesehenen Container-Objekten erzeugt und gesteuert. Dazu gehört z.B. das Ein- und Ausblenden sowie die Anpassung an aktuelle Messwerte. Einen Ausschnitt dieser Hierarchie stellt Abbildung \ref{img:hirarch} dar.\\

\begin{wrapfigure}{r}{0.5\textwidth}
	\centering
	\includegraphics[width=0.48\textwidth]{images/unity/hirarchy.jpg}
	\caption{Hierarchie der einzelnen Darstellungsobjekte.}
	\label{img:hirarch}
\end{wrapfigure}

\textbf{Die Felddarstellungen}\\
Die 3D-Objekte der Magnetfelder wurden in Blender erstellt, in Unity importiert und als vorgefertigte Objekte gespeichert. Diese werden von Skripten zur Laufzeit instanziiert. Als Shader kommt der Standard-MRTK Shader mit den entsprechenden Einstellungen für Farbe und Transparenz zum Einsatz. Die Transparenz kann auf so jedoch nicht immer korrekt berechnet werden, wenn Teile eines Objektes sowohl vor als auch hinter einem anderen, transparenten Objekt liegen. Hier wurden jedoch aufgrund der zeitlichen Begrenzung und dem begrenzten Auftreten des Problems keine weiteren Maßnahmen, wie z.B. die Aufteilung der Geometrie in mehrere Objekte, ergriffen.\\

\textbf{Vorberechnete Darstellung des Magnetfeldes}\\
Die numerische Lösung der Feldgleichungen erfolgte mittels der Simulationssoftware COMSOL Multiphysics. Diese Arbeit konnte auf eine bestehende Implementierung einer Helmholtz-Spule aufbauen. Hier wurden lediglich die folgenden Parameter für die Berechnung der Feldlinien gesetzt:
\begin{itemize}
	\setlength{\itemsep}{-1pt}
	\singlespacing
	\item Kugelvolumen für Begrenzung der Simulation auf zwei Meter gesetzt, maximale Granularität
	\item 12 Feldlinien mit Anfangspunkten der X-Achse
	\item Qualitätseinstellungen der Darstellung auf Maximum gesetzt
\end{itemize}

Die Einstellung der maximal möglichen Qualität liegt darin begründet, Artefakte durch Ungenauigkeiten der Berechnung zu vermeiden. Bei geringeren Qualitätseinstellungen traten unter anderem asymmetrische Feldlinien auf, die physikalisch nicht korrekt sind und zu Irritationen führen würden.\\

\textit{Export, Import, Datenformat}\\
Das Ergebnis der Simulation ist eine Liste von Datenpunkten der Form \textbf{[}\textit{FeldlinienNr:} Int, \textit{Position:} Vector3, \textit{Betrag der Flussdichte:} float\textbf{]}. Dafür wurde ein CSV-Reader geschrieben, der die Daten zur Laufzeit der Applikation einliest, interpretiert und zum Rendering an GameObjects weitergibt. Folglich ließen sich weitere Simulationen vorberechnen und anzeigen. Das Einlesen der Daten erfolgt beim Startvorgang.\\

\textit{Filtering}\\
Aufgrund der hohen Qualitätseinstellungen liefert die Simulationssoftware eine große Menge an Datenpunkten. Die verwendete Berechnung enthält knapp 12.000 Datenpunkte, die im Rahmen der limitierten Ressourcen nicht alle dargestellt werden können\footnote{Ein Test mit knapp 9.000 Punkten führte zu einer CPU-Zeit von ca. 45 ms pro Frame und einer Framerate von ca. 20 FPS.}. Daher wird ein Filter angewandt, der beim Einlesen eines Exportes nur Datenpunkte behält, die einen räumlichen Mindestabstand zum vorangegangenen Wert einhalten. Außerdem werden doppelt gezogene Linien erkannt und entfernt. Durch dieses Vorgehen reduziert sich die Datenmenge auf ca. 1.600 Datenpunkte. Dabei entsteht jedoch kein wahrnehmbarer Qualitätsverlust der Darstellung.\\

\textit{Rendering}\\
Die Darstellung erfolgt über Unity's Low-Level \textit{Graphics Library (GL)} mittels eines Line-Strips. Dieser ist vergleichbar mit dem von OpenGL, hat aber weniger Funktionen. Insbesondere lässt sich die Dicke der Linien nicht einstellen, sondern ist auf einen Pixel festgelegt. Der sonst in dieser Arbeit für Linien genutzte LineRenderer konnte hier nicht verwendet werden, denn letzterer ermöglicht für eine Linie nur die Interpolation zwischen maximal 8 Farben. Eine besser Konfigurierbare Darstellung wäre z.B. über eine 3D-Geometrie möglich.\\

\textbf{Der Stromfluss}\\
Die Indikatoren werden mit Unity's LineRenderer dargestellt und sind bezüglich ihrer Größe, Positionierung und Ausrichtung parametrisiert. Bei der Annotationen der Anschlüsse konnte auf ein vorgefertigtes Tooltip-Objekt des MRTK zurückgegriffen werden. Dies wurde um die entsprechenden Farben und Icons ergänzt. Die Icons basieren auf freien Icon-Packeten \footnote{https://icons8.com}, wurden jedoch angepasst. Da schwarze Strukturen vor transparentem Grund auf der HoloLens so nicht zu sehen sind, wurde der Hintergrund bzw. die Icon-Struktur zu weiß geändert.\\

\textbf{Kompass}\\
Die verschiedenen Kompasslinien werden ebenfalls durch einen LineRenderer gezeichnet. Um eine gestrichelte Linie zu erhalten, wird eine Textur mit weißem Kreis vor transparentem Hintergrund auf die Länge der Linie mittels Tiling skaliert. Ein dazu angefertigtes Skript übernimmt diesen Vorgang automatisch.\\

\textbf{Berechnung der Verdeckung}\\
Für die Verdeckungsberechnung wurde die Spule anhand gemessener Größen in Blender manuell nachmodelliert. Das Spatial Mapping der HoloLens ist hier zu ungenau, um eine glaubwürdige Verdeckung zu ermöglichen. In der Standard-Einstellung wird die Spule gar nicht erkannt, was wohl auch dem Material (Kupfer) geschuldet sein dürfte. Eine Darstellung des Spatial Mappings des Versuchsaufbaus ist in Abb. \ref{img:mesh-vs-model} zu sehen.
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.45\textwidth]{images/HL/mesh.jpg}
	\caption{Spatial Mapping der Gerätschaften. Während die Spannungsquelle gut zu sehen ist, ist die Spule lediglich als Unebenheiten im Tisch zu erkennen. Die entsprechende Stelle ist durch eine Ellipse markiert.}
	\label{img:mesh-vs-model}
\end{figure}
Die Geometrie wird ausschließlich in den Tiefenpuffer gerendert\footnote{Der entsprechende Shader ist nur wenige Zeilen lang und findet sich in verschiedenen Varianten im Internet. Dieser orientiert sich an http://wiki.unity3d.com/index.php/DepthMask}. Das vermeidet überflüssige Draw Calls und folgt der Empfehlung der Dokumentation. Damit virtuelle Objekte aber auch dann noch verdeckt bleiben, wenn reale Objekte nah kommen, muss das Near Clipping Plane sehr nah am Kameraursprung liegen. Andernfalls würden weiter entfernte, virtuelle Objekte plötzlich doch vor realen Objekten angezeigt werden, sobald letztere zu nah sind und das Clipping die für die Verdeckung eingesetzten Objekte vom Rendering ausschließt. Das stellt bei dieser Lösung aber kein Problem dar, weil zu nahe, virtuelle Objekte ohnehin über ein eigenes Verhalten ausgeblendet werden, das nicht auf die Clippingebene aufbaut.\\


\textbf{Near Plane Fading}\\
Statt auf Basis der Clippingebene werden zu nahe Objekte über Skripte bzw. Shader kontinuierlich ausgeblendet. Dieses Verhalten ist für den Nutzer angenehmer als ein plötzliches Aufpoppen bzw. Verschwinden von Objekten in unmittelbarer Nähe.\\

Der für die meisten Objekte genutzt MRTK Standard Shader bietet bereits einen konfigurierbaren Bereich, über den Objekte ausgeblendet werden. Für andere Elemente wird die Transparenz über ein Skript geregelt. Hier werden für die Grenzen des Bereiches, über den zur Transparenz übergegangen wird, die empfohlenen Werte von 85 cm und 50 cm genutzt. Lediglich die Linien des Kompasses werden von 75 cm bis 40 cm ausgeblendet, damit die Ausrichtung der Nadel entlang der Linien auch aus geringerem Abstand erfasst werden kann. Insgesamt ergibt sich die Transparenz (Alpha-Wert) eines Objektes dann aus dem Minimum der Werte durch die verschiedenen Effekte.\\

Diese Lösung geht jedoch zu Lasten der Performance, denn für die Transparenz werden alle betroffenen Objekte von hinten nach vorne (aus Sicht der Kamera) gerendert. Auch Pixel, die durch weiter vorne gelegene Objekte eingenommen werden, müssen mehrfach gezeichnet werden, da die dichteren Objekte ggf. transparent sind und durch die Farbe anderer Objekte beeinflusst werden. Dieser sogenannte Overdraw nimmt zusätzliche Rechenzeit in Anspruch. Eine Alternative bestünde darin, Objekte schwarz anstatt transparent werden zu lassen. Auf der HoloLens macht dies optisch zunächst keinen Unterschied, da Schwarz auf der Brille nicht dargestellt wird. Allerdings bliebe so die Verdeckung durch bereits verschwundenen Objekte bestehen, was zu Irritationen führen würde.\\

Aus Zeitgründen wurde das Fading für das Datenpanel, die Konnektoren der Tooltips und die Linien der Simulationsdarstellung nicht umgesetzt.\\

\textbf{Beleuchtung der Szene}\\
Die virtuellen 3D-Objekte werden durch eine Lichtquelle oberhalb der Spule beleuchtet. Eine Schattenberechnung erfolgt nicht. Tests mit realen Gegenständen ähnlicher Größe ergaben, dass die Objekte bei typischen Lichtverhältnissen keine erkennbaren Schatten werfen würden.\\

\textbf{Kantenglättung}\\
Bei Darstellungen auf der HoloLens fällt der Kantenglättung eine besondere Bedeutung zu. Im Gegensatz zu anderen Anwendungen, bei denen der Nutzer die Kamera über herkömmliche Eingabegeräte steuert, ist bei der Brille die Kamera an die Kopfbewegungen des Trägers gebunden. Die Displays folgen daher den ständigen, feinen Vibrationen des Kopfes und die Kamera steht somit nie still. Deshalb können Treppeneffekte an Kanten besonders auffällig und störend wirken, da das resultierende Kantenflimmern dauerhaft präsent ist.\\

Unity unterstützt standardmäßig einige Anti-Aliasing Verfahren. Dazu gehört Multisample Anti-Aliasing (MSAA), das ohne weitere Maßnahmen für die Kamera aktiviert werden kann. Im Gegensatz dazu benötigen die anderen Methoden Deferred Shading und würden eine Umstellung des Rendering Path bedeuten\footnote{Standardmäßig angeboten werden außerdem Fast Approximate AA und Temporal AA}. Im Rahmen dieser Arbeit wurde deshalb nur MSAA in Betracht gezogen.\\

Vor allem für die gewählte Visualisierung der Simulationsdaten über Linien ist eine Form des Anti-Aliasing relevant, da hier besonders viele Kanten entstehen. Deshalb wurde sich für Einsatz von zweifachem MSAA entschieden, obwohl damit erheblicher Rechenaufwand verbunden ist.

\subsubsection{Implementierung der Interaktion}

Die Interaktion erfolgt, wie in Kap. \ref{sec-4-4} beschrieben, durch Klicks. Sprachbefehle wurden aus Zeitgründen nur für Debugging-Funktionen implementiert. 
Während des Hauptteils der Anwendung belaufen sich die möglichen Aktionen auf:

\begin{itemize}
	\setlength{\itemsep}{-1pt}
	\singlespacing
	\item Klick: Wechsel zwischen den beiden Echtzeitdarstellungen
	\item Doppelklick: Wechsel zwischen Simulations- und Echtzeitdarstellungen
	\item Hold-Klick: Aufrufen des Hauptmenüs
\end{itemize}

Für die letzteren beiden wurden entsprechende Skripte geschrieben, die diese Gesten erkennen. Zwar erkennt das MRTK bereits eine Hold-Geste, allerdings kann hier der Nutzer beliebig lange gedrückt halten und erst beim Loslassen feuert das entsprechende Event. Zum Aufrufen des Menüs ist jedoch ein Verhalten wünschenswert, bei dem nach kurzem Gedrückt-Halten das Menü erscheint. Daher wurde hier eine eigene Lösung entwickelt.\\

Jeder Klick wird durch einen Klick-Sound begleitet, der als Feedback dient. Ist der Cursor aktiv, bietet dieser auch ein visuelles Feedback. Als Klick-Sound wurde ein Standard-Sound des MRTK verwendet, der auch von den Buttons genutzt wird.\\

\textit{Progress Indikator}\\
Um den Anwender über länger laufende Prozesse zu informieren, kommt eine Fortschrittsanzeige zum Einsatz. Hier kann auf den aus Mircosoft Windows bekannten Indikator zurückgegriffen werden, den das MRTK als vorgefertigtes Objekt anbietet. Abbildung \ref{img:pi-load} zeigt diesen beim Start der Anwendung.\\

\begin{wrapfigure}{r}{0.5\textwidth}
	\centering
	\includegraphics[width=0.45\textwidth]{images/unity/loading.jpg}
	\caption{Logo und Progress Indikator beim Startvorgang der Anwendung}
	\label{img:pi-load}
\end{wrapfigure}

Für die Kommunikation mit dem Nutzer ist bei dieser Anwendung vor allem wichtig, was das System tut. Längere Ladezeiten o.Ä. treten hier nicht auf, daher wird lediglich das Text-Element des Indikators verwendet, von der prozentualen Anzeige wird nicht Gebrauch gemacht. Komponenten, die den Indikator nutzen, stellen jedoch stets sicher, dass eine Nachricht lange genug sichtbar ist, um gelesen werden zu können. Länger laufende Operationen sind stets asynchron umgesetzt, die pro Frame nur einen Teil der Arbeit erledigen und so den Renderprozess nicht blockieren.\\

\textit{Tracking}\\
Für das Erkennen der Markerposition kommt das Tracking Framework Vuforia zum Einsatz. Ein optischer Marker wird vor der Spule auf dem Untergrund platziert. Dieser wird dann über die Frontkamera der HoloLens durch das Framework erkannt und die Position und Ausrichtung bestimmt. Die Modelle werden entsprechend positioniert und ein World Anchor gesetzt. Damit ist die Positionierung abgeschlossen und der Marker kann entfernt werden. Da Vuforia nur während dieser Sequenz aktiviert ist, werden für den Rest der Anwendung Hardwareressourcen frei. Allerdings muss der Nutzer für die Erkennung den Marker fokussieren und im Sichtfeld der Kamera behalten. Kopfbewegungen sollten dabei vermieden werden, um die Erkennung nicht zu beeinträchtigen.\\

Dieser Vorgang lässt sich über das Menü jederzeit neu anstoßen und die einzelnen Schritte werden über den Progress Indikator dem Nutzer kommuniziert. Die Steuerung des Prozesses erfolgt durch den \textit{Tracking Manager}. Dieser startet und stoppt das Framework, reagiert auf Änderungen im Tracking und informiert den Anwender über den Fortschritt. In der aktuellen Version funktioniert das nochmalige Anstoßen des Tracking-Vorgangs jedoch nur in der Entwicklungsumgebung und noch nicht auf der HoloLens.\\

\textit{Einstellungen}\\
Die Einstellungen sind über ein dem Daten-Panel ähnlichen Objekt realisiert, das in Abbildung \ref{img:menu-and-settings} zu sehen ist. Ein Klick auf eines der Input-Felder ruft die virtuelle Tastatur hervor, beide werden durch das MRTK bereitgestellt und wurden hier für numerische Eingaben konfiguriert. Die Werte werden als JSON formatiert und in das AppData-Verzeichnis der Anwendung gespeichert. Damit stehen sie auch nach einem Neustart oder Update der App noch zur Verfügung. Die Applikation sucht beim Start automatisch nach gespeicherten Einstellungen und lädt entweder diese oder die Default-Werte. Andere Komponenten werden durch ein Event über sich ändernde Einstellungen benachrichtigt und passen sich entsprechend an. Für die Formatierung als JSON wurde eine vorhandene Implementierung genutzt \cite{Goebel17}.\\

\begin{figure}[H]
	\centering
	\includegraphics[width=0.48\textwidth]{images/HL/menu_c.jpg}
	\hspace{0.02\textwidth}	
	\includegraphics[width=0.48\textwidth]{images/HL/settings_c.jpg}
	\caption{Aufnahmen von Menü und Einstellungen der HoloLens-Anwendung.}
	\label{img:menu-and-settings}
\end{figure}

\textit{Menü}\\
Die Umsetzung des Menüs ist ebenfalls in Abbildung \ref{img:menu-and-settings} dargestellt. Die Form der Buttons wurde so angepasst, dass die Labels und Icons problemlos darauf Platz finden. Bei den Icons wurde auf Standard-Elemente aus dem MRTK zurückgegriffen. Das Menü wird über den \textit{MenuController} gesteuert, von dem aus alle weiteren Vorgänge gestartet werden. Dieser aktiviert auch den Cursor, der zur Nutzung von Menu und Einstellungen dient. Sowohl das Menü, als auch die Ladeanzeige und die Einstellungen werden durch Skripte der Kameraposition angepasst und folgen dieser in festgelegten Bereichen für Abstand und Winkel. Die Skripte werden durch das MRTK bereitgestellt.\\

\textit{Intro-Sequenz}\\
Es wurde eine Startsequenz entwickelt, die Aufgaben wie das Laden von Daten und Einstellungen und die Initialisierung der einzelnen Komponenten übernimmt. Hier wird ein Logo in Form eines größeren Schriftzuges und dazu der Progress Indikator angezeigt. Letzterer informiert über den Zustand des Ladevorgangs. Während des Vorgangs werden insbesondere die Einstellungen und Simulationsdaten geladen.\\

Diese Umsetzung erlaubt die notwendigen Ladevorgänge und ist für den Nutzer nachvollziehbar. Außerdem gibt das letzterem einige Sekunden Zeit, um sich auf die Anwendung einzustellen, bevor das Menü erscheint und eine Aktion vom Anwender verlangt.

\vspace{8px}
\begin{center}
	\fbox{
		\parbox{0.9\linewidth}{
			\vspace{4px}
			\textbf{Zusammenfassung}
			\begin{itemize}[rightmargin=12px, topsep=-12px]
				\setlength{\itemsep}{-1pt}
				\singlespacing
				\item Tracking mit Vuforia, nur zum Erkennen des Markers aktiv
				\item Einstellungen werden als JSON-Datei im AppData Verzeichnis gespeichert
				\item Menü übernimmt Steuerung der einzelnen Vorgänge, jederzeit aufrufbar
				\item Startvorgang mit Intro-Sequenz lädt Daten und Einstellungen und initialisiert Komponenten
			\end{itemize}
			\vspace{18px}
	}}\\
\end{center}
\vspace{6px}

\subsubsection{Performance-Optimierungen}
Zuletzt sollen einige Maßnahmen genannt werden, die zu einem geringeren Ressourcenverbrauch der Applikation beitragen. Zunächst ist festzuhalten, dass die durch das MRTK voreingestellten Qualitätseinstellungen genutzt wurden. Einzige Ausnahme stellt hier die Kantenglättung dar. Darüber hinaus wurden die folgenden Einstellungen angewandt:

\begin{itemize}
	\setlength{\itemsep}{-1pt}
	\singlespacing
	\item Single Pass Instanced Rendering
	\item Größe des Tiefenpuffers auf 16-Bit gesetzt (Minimum)
	\item Vuforia nur für den Vorgang der Positionsbestimmung aktiv
	\item Physics Enginge deaktiviert
	\item Occlusion Mesh wird ausschließlich in Z-Puffer gerendert
	\item Unsichtbare (vollst. transparente) Objekte werden meist deaktiviert
	\item Reduktion der Simulationsdaten auf ca. 13\%
\end{itemize}

Diese Maßnahmen basieren vorrangig auf den Empfehlungen zur Performance in der Dokumentation.